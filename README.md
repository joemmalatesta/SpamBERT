# [SpamBERT](https://huggingface.co/spaces/joemmalatesta/SpamBERT)
SpamBERT is a BERT NLP Model that has been fine tuned to detect text message spam. The purpose of this model is to weed out spam and potentially harmful sms messages.

## Usage
SpamBERT is incredibly easy to use. Simply submit text in the input box at this [HuggingFace Space](https://huggingface.co/spaces/joemmalatesta/SpamBERT) and the fine tuned model will evaluate whether or not your input message is "ham" (not spam) or "spam". 

## Running Locally
This code could be run locally if the `model.safetensors` was included in the SpamBERT folder (and is present in the files of my HuggingFace Space) simply by running the `app.py` with the correct dependencies. The general purpose BERT model, after 3 epochs (and 3 hours) of fine tuning on the data found in this [dataset](https://huggingface.co/datasets/sms_spam) in an 80/20 training/testing split became very refined and correctly evaluates SMS Spam messages found online as well as those generated by GPT-4.

## Documentation
#### Pretrained BERT Model
- Model: BERT is a bidirectional model designed for classifying sequences of text and builds on the Transformer structure, which uses layers of self-attention mechanisms.
- Architecture: BERTâ€™s architecture include several layers, each containing mechanisms for focusing on different parts of the text and processing sequences in detail.
- Capabilities: BERT's bidirectional design allows it to effectively understand the context of each word within a sentence, making it suitable for a variety of NLP tasks such as sequence classification and sentiment analysis.

#### Dataset
- [`sms_spam`](https://huggingface.co/datasets/sms_spam) dataset from Hugging Face datasets library.
- Public Set of SMS Labeled messages that were collected for mobile phone spam research. 
- All messages are English, with 87% of messages being marked `Ham` (legitimate) and 13% being marked as `Spam`

#### Training
Starting point
`{'loss': 0.7044, 'grad_norm': 13.863030433654785, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.02}`
Epoch 1
- `{'eval_loss': 0.049509886652231216, 'eval_accuracy': 0.9919282511210762, 'eval_f1': 0.9706840390879479, 'eval_precision': 0.9933333333333333, 'eval_recall': 0.9490445859872612, 'eval_runtime': 274.153, 'eval_samples_per_second': 4.067, 'eval_steps_per_second': 0.255, 'epoch': 1.0}`
Epoch 2
- `{'eval_loss': 0.05400243028998375, 'eval_accuracy': 0.9919282511210762, 'eval_f1': 0.9706840390879479, 'eval_precision': 0.9933333333333333, 'eval_recall': 0.9490445859872612, 'eval_runtime': 275.185, 'eval_samples_per_second': 4.052, 'eval_steps_per_second': 0.254, 'epoch': 2.0}`
Epoch 3
`{'loss': 0.0001, 'grad_norm': 0.0022204192355275154, 'learning_rate': 1.7035775127768315e-07, 'epoch': 2.99}` (Didn't record full output, sorry)

#### Frameworks
- Transformers from HuggingFace provided the tooling for Loading the dataset and BERT model, and fine tuning the model. 
- Gradio was used to create the User Interface 
- HuggingFace Spaces was used for hosting the Gradio portion of the project.
- Training was done locally on my own PC 
  
#### Gradio demo
The demo created with Gradio is as simple as can be, with the only variable being a single text input box. After the text is input and the user presses submit, the text input is tokenized using BERT's tokenizer and then the fine tuned model makes it's prediction based on the tokenized data, outputting logits transformed into class probabilities. With the output standardized to either a 0 or 1, it is simple to provide either a "Spam" or "Ham" output to the user.

## Contributions
In the creation of SpamBERT, I fine-tuned the classic BERT model on SMS Spam data in order to provide a strong evaluation of text messages for spam content. In doing this, I wrote the code for loading the model and dataset, and training of the model. I used my local machine to fine tune this model, and saved the outputs in the `SpamBERT` folder so I could reuse them and upload them to my HuggingFace Space. After the training was complete, I wrote the code for a simple Gradio application that would load the fine tuned model and make the predictions based on the input provided by the user. This was not my original idea but after troubles with Google Colab, Loading the GPT-2 Model locally, and Scraping the web for data, I decided on a bit of a simpler idea that would still teach me the important parts of fine tuning a model and creating a simple UI for it.


## Limitations
While the model does a pretty good job filtering out potentially harmful messages, or just ones you don't want coming to your inbox, there are some incorrect evaluations when you purposefully blur the lines between spam and ham. For example, the text message `Hey, check out this amazing deal I found for us! http://bit.ly/AmazingDeal Let's get it if you're interested.` Is evaluated as `Spam` although it could reasonably be a message from your friend. I've found that many texts with Links or things like `Text YES to reply` are marked as spam when they could be things you want. There are definitely more false positives (Marked Spam when it is Ham) which, for a system like this is actually better than more missed spam messages.

## Examples
#### Spam
- Hey there! You've been selected for a FREE iPhone. Enter code 'FREE' at our site to get yours now.
- URGENT! You have won a free trip to Bahamas. Call now +1234567890 to claim your tickets.
- "Win $$$ now!!! Send 'PLAY' to 5000 and get cash today! Ts&Cs apply. Stop to opt out." 
#### Ham
- Got the tickets for the concert. I'll send them to your email.
- Reminder: Dentist appointment at 3 PM tomorrow.
- Can you send me the report by EOD? Thanks!
#### False Positives
- Hey, check out this amazing deal I found for us! http://bit.ly/AmazingDeal Let's get it if you're interested.
- Join us for a free yoga session this Sunday at 10 AM in Central Park! Text YES to confirm your spot.

